# -*- coding: utf-8 -*-
"""prueba_video.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OYeSoRY8Hb5T--_7p2YEusFu2s7l5Tvi
"""

!git clone https://github.com/vladip11/ProyectoSIS330.git

cd ProyectoSIS330/

!python setup.py install

import os
import sys
import json
import numpy as np
import time
from PIL import Image, ImageDraw
import skimage.draw
import random
import colorsys
import cv2
from google.colab.patches import cv2_imshow


ROOT_DIR = '/content/ProyectoSIS330/'
assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist'

sys.path.append(ROOT_DIR) 

from mrcnn import visualize
from mrcnn.config import Config
from mrcnn import model as modellib, utils



class CustomConfig(Config):
    """Configuration for training on the helmet  dataset.
    """
    # Give the configuration a recognizable name
    NAME = "object"

    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    # Number of classes (including background)
    NUM_CLASSES = 1 + 6  # background + objetos

    # All of our training images are 512x512
    IMAGE_MIN_DIM = 512
    IMAGE_MAX_DIM = 1472

    # You can experiment with this number to see if it improves training
    STEPS_PER_EPOCH = 500

    # This is how often validation is run. If you are using too much hard drive space
    # on saved models (in the MODEL_DIR), try making this value larger.
    VALIDATION_STEPS = 5
    
    # Matterport originally used resnet101, but I downsized to fit it on my graphics card
    BACKBONE = 'resnet50'

    # To be honest, I haven't taken the time to figure out what these do
    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)
    TRAIN_ROIS_PER_IMAGE = 32
    MAX_GT_INSTANCES = 50 
    POST_NMS_ROIS_INFERENCE = 500 
    POST_NMS_ROIS_TRAINING = 1000 
    
config = CustomConfig()

class InferenceConfig(CustomConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    #IMAGE_MIN_DIM = 512
    IMAGE_MAX_DIM = 1472
    DETECTION_MIN_CONFIDENCE = 0.9
inference_config = InferenceConfig()

# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, "/content/drive/MyDrive/miColab")

# Local path to trained weights file
model_path = os.path.join(ROOT_DIR, "/content/drive/MyDrive/miColab/mask_rcnn_object_0010.h5")

# Download COCO trained weights from Releases if needed
#if not os.path.exists(COCO_MODEL_PATH):
 #   utils.download_trained_weights(COCO_MODEL_PATH)

model = modellib.MaskRCNN(mode="inference", config=inference_config,  model_dir=MODEL_DIR)

#model_path = model.find_last()
# Load trained weights (fill in path to trained weights here)
assert model_path != "", "Provide path to trained weights"
print("Loading weights from ", model_path)
model.load_weights(model_path, by_name=True,exclude=["mrcnn_class_logits", "mrcnn_bbox_fc", 
                                "mrcnn_bbox", "mrcnn_mask"])

class_names = ['BG', 'persona','p_comiendo','plato_vacio','plato_lleno','llajuero_lleno','llajuero_vacio']
#camera = cv2.VideoCapture(1)
camera = cv2.VideoCapture("/content/drive/MyDrive/miColab/video06.mp4")

while camera:
    ret, frame = camera.read()
    frame = cv2.resize(frame, (640, 480), interpolation = cv2.INTER_AREA)

    results = model.detect([frame], verbose=0)
    r = results[0]
    
    N =  r['rois'].shape[0]
    boxes=r['rois']
    masks=r['masks']
    class_ids=r['class_ids']
    scores=r['scores']
    for i in class_ids:
      print(class_names[i])
    hsv = [(i / N, 1, 0.7) for i in range(N)]
    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))
    
    random.shuffle(colors)
    #print("N_obj:",N)
    masked_image = frame.astype(np.uint32).copy()
    
    for i in range(N):
        
        if not np.any(boxes[i]):
            # Skip this instance. Has no bbox. Likely lost in image cropping.
            continue

        color = list(np.random.random(size=3) * 256)
        mask = masks[:, :, i]
        alpha=0.5

        
        for c in range(3):
            masked_image[:, :, c] = np.where(mask == 1,
                                  masked_image[:, :, c] *
                                  (1 - alpha) + alpha * color[c],
                                  masked_image[:, :, c])
            
        
        frame_obj=masked_image.astype(np.uint8)
        y1, x1, y2, x2 = boxes[i]
        cv2.rectangle(frame_obj, (x1, y1), (x2, y2),color, 2)  
        
        class_id = class_ids[i]
        score = scores[i] if scores is not None else None
        label = class_names[class_id]
        caption = "{} {:.3f}".format(label, score) if score else label
        cv2.putText(frame_obj,caption,(int(x1), int(y1)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        masked_image = frame_obj.astype(np.uint32).copy()
    
        
    if N>0:
        cv2_imshow(frame_obj)
        #cv2.imshow('frame', frame_obj)
    else:
        cv2_imshow(frame)
        #cv2.imshow('frame', frame)
    
    if cv2.waitKey(25) & 0xFF == ord('q'):
        break;
        
camera.release()
cv2.destroyAllWindows()

